{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnwz5xIb6pNWVWdBW3vMoR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MAHE0609/python/blob/main/AD_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpecVfYJyDhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1) mention about problem statement\n",
        "##2) talk about columns\n",
        "##3)install the models and required libraries\n",
        "##4)load data set\n",
        "##5)understand your data\n",
        "##6)EDA\n",
        "## i)univariate analysis\n",
        "## ii)Bi-variate analysis\n",
        "## iii)multivariate analysis\n",
        "## 7) check the null values or missing values\n",
        "## i)treating the null values(fill with mean or median or mode)\n",
        "## ii)drop null values if they are less than 5%-10%\n",
        "##8)check the duplicates\n",
        "## i)drop the duplicates\n",
        "##9)treating the outliers\n",
        "## i)check the outliers\n",
        "## ii)remove the outliers\n",
        "## iii)make box plots before and after outliers\n",
        "##10)feature engineering\n",
        "## i)extract the features\n",
        "## ii)create the features\n",
        "## iii)select the features\n",
        "#3 b)checking the multicoliniarity\n",
        "## i)heat map\n",
        "## ii)vif technique\n",
        "## c)transformation\n",
        "## i)one hor encoding or label encoding\n",
        "## 11)x-y features split\n",
        "## 12)train test split\n",
        "\n",
        "## for classification\n",
        "##1) apply smote technique\n",
        "##2)build the models\n",
        " ##i)logistic regression\n",
        " ##ii)decision tree\n",
        " ##iii)random fotrest\n",
        " ##iv)gradient  boost\n",
        " ##v) ada boost\n",
        " ##vi)Knn\n",
        " ##vii)svm\n",
        " ##viii)navie bayes\n",
        " ##3) Hyper parameter tuning\n",
        " ##i)cross validation\n",
        " ##4)deploy the best model; in streamlit or flask\n",
        "\n",
        "## for regression\n",
        "##1)apply models\n",
        " ##i)Linesr regression\n",
        " ##ii)decision tree\n",
        " ##iii)random forest\n",
        " ##iv)gradient boost\n",
        " ##v)Knn\n",
        " ##vi)svm\n",
        "\n",
        "### for recommendation engine\n",
        "Steps for Building a Recommendation Engine:\n",
        "1.\tLoading Data\n",
        "2.\tData Preprocessing\n",
        "3.\tExploratory Data Analysis (EDA)\n",
        "4.\tFeature Engineering\n",
        "5.\tChoosing a Recommendation Approach (Collaborative Filtering, Content-Based, Hybrid, etc.)\n",
        "6.\tBuilding the Recommendation Model\n",
        "7.\tTraining the Model\n",
        "8.\tEvaluating the Model (Precision, Recall, RMSE, etc.)\n",
        "9.\tHyperparameter Tuning\n",
        "10.\tSelecting the Best Model\n",
        "11.\tModel Deployment.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JdwerFDWyIvk"
      }
    }
  ]
}